---
title: "Assignment 2: Parallelisation"
author: "Mishka Ramraj"
format: html
---


### Requirements

My Github respository link: https://github.com/Mishka312/StatHonPrac2/tree/main  



Load necessary packages: 

```{r, output = F}

library(doParallel)
library(foreach)
library(MASS)
library(boot)
library(iterators)
library(knitr)
```


## Question 1

Below is the code associated with 2 methods. The first uses foreach() for a sequential functionality and the second for parallelisation.

```{r}

exp_random <- function() {
  sample <- rexp(1000, 1)
  m <- mean(sample)
  v <- var(sample)
  
  vals <- list(mean = m, variance = v)
  
}


## Sequentially
results1.1 <- foreach(i = 1:100, .combine = rbind) %do% {
  exp_random()
}


## Parallelisation

cl <- makeCluster(detectCores() - 1)
registerDoParallel(cl)

results1.2 <- foreach(i = 1:100, .combine = rbind) %dopar% {
  exp_random()
}

stopCluster(cl)

```


## Question 2

Table 1.1 displays that sequential methods are quicker when just considering one bootstrap sample at a time. However, when considering 100 Bootstraps samples at a time, parallelisation yields a shorter time. In this demonstration, parallelisation using multiple bootstraps samples at once was faster by about 2.7 seconds.


```{r, results = 'asis', echo = F}


## Single bootstraps----------------------
Bstrap <- function() {
  bs <- sample(galaxies, replace = T)
  med <- median(bs)
  
  return(med)
}

### PARALLELISATION

TrueMed <- median(galaxies) #20833.5

t1 <- system.time({
  cl <- makeCluster(detectCores() - 1)
  registerDoParallel(cl)
  
  results2.1 <- foreach(i = 1:100, .combine = rbind, .packages='MASS') %dopar% {
    Bstrap()
  }
  
  stopCluster(cl)
})

### SEQUENTIAL

bs_vals <- numeric(100)


t2 <- system.time({
  for (i in 1:100) {
    bs_vals[i] <- Bstrap()
  }
})

## multiple bootstraps----------------------

multiple_BS <- function() {
  mBS <- numeric(1000)
  for (i in 1:1000) {
    mBS[i] <- Bstrap()
  }
  return(invisible(mBS))
}

multiple_BS()


### PARALLELISATION

t3 <- system.time({
  cl <- makeCluster(detectCores() - 1)
  registerDoParallel(cl)
  
  results2.2 <- foreach(i = 1:100, .combine = rbind, .packages='MASS') %dopar% {
    multiple_BS()
  }
  
  stopCluster(cl)
  
})

### SEQUENTIAL

t4 <- system.time({
  for (i in 1:100) {
    multiple_BS()
  }
})


# Compare program times

single_parallel <- t1
single_sequential <- t2
multiple_parallel <- t3
multiple_sequential <- t4

t <- rbind(single_parallel, single_sequential, multiple_parallel, multiple_sequential)

knitr::kable(t, caption = "Time taken to perform bootstrapping tasks using sequential and parallelised methods.")


```


## Question 3 

In order to estimate the coverage of a bootstrap confidence interval, a sample was taken from the exponential(1) distribution. From this, the sample statistic (mean) was calculated and 100 boostraps taken. A 95% confidence interval was constructed. This process was repeated 1000 times so that we accumulated 1000 bootstrap confidence intervals. From all of these, the proportion of confidence intervals containing the true mean (1) was calculated. This told us the *coverage* of the bootstrap confidence intervals.

```{r, echo = F}


original_samp <- function() {
  
  os <- rexp(50, 1)
  return(invisible(os))
}



bs <- function(x) {
  
  bs <- sample(x, replace = T)
  bs_mean <- mean(bs)
  return(bs_mean)
}


encompass <- function() {
  os <- original_samp()
  
  bs_means <- numeric(1000)
  
  for (i in 1:1000) {
    bs_means[i] <- bs(os)
  }
  
  quants <- quantile(bs_means, probs = c(0.025, 0.975))
  
  OS_mean <- mean(os)
  
  CI <- sort(c(2*OS_mean - quants[2], 2*OS_mean - quants[1]))
  #CI2 <- boot.ci(bs_means, type = "perc")
  
  
  return(CI)
  
}

#encompass()

# repeat encompass function multiple times eg 1000
# will use parallelisation


cl <- makeCluster(detectCores() - 1)
registerDoParallel(cl)

results3.1 <- foreach(i = 1:1000, .combine = rbind) %dopar% {
  encompass()
}

stopCluster(cl)

counter <- numeric(nrow(results3.1))

for (i in 1:nrow(results3.1)) {
  if (results3.1[i, 1] < 1) {
    if (results3.1[i, 2] > 1) {
      counter[i] <- 1
    }
  } else{
    counter[i] <- 0
  }
}

coverage <- sum(counter)/ length(counter)
#coverage


```

In this scenario, the value for coverage is `r coverage`.



## Question 4 

Below is the code to find the maximum of 3 vectors of length 5 using foreach and an iterator object from irnorm().  

The resultant maximum values are shown below

```{r, echo = T}

set.seed(1234)

iterator <- irnorm(n = 5, mean = 1, sd = 1)

results4.1 <- foreach(i = 1:3, .combine = cbind, .packages='iterators') %do% {
  print(max(nextElem(iterator)))
}

```


## Question 5

The following table depicts that the foreach used for sequential functionality and the replicate method were the fastest methods. Using parLapply worked in 0.4 seconds and the foreach using parallelisation took the longest - o.47 seconds.
```{r, echo = F}

foreach_do_time <- system.time({
  
  iterator <- irnorm(n = 5, mean = 1, sd = 1)
  
  results5.1 <- foreach(i = 1:3, .combine = cbind, .packages='iterators') %do% {
    res5.1 <- max(nextElem(iterator))
  }
  
})


foreach_dopar_time <- system.time({
  
  iterator <- irnorm(n = 5, mean = 1, sd = 1)
  
  cl <- makeCluster(detectCores() - 1)
  registerDoParallel(cl)
  
  results5.2 <- foreach(i = 1:3, .combine = cbind, .packages='iterators') %dopar% {
    res5.2 <- max(nextElem(iterator))
  }
  
  stopCluster(cl)
  
})


##replicate time----------------

replicate_time <- system.time({
  
  iterator <- irnorm(n = 5, mean = 1, sd = 1)
  
  replicate(3, max(nextElem(iterator)))
  
})


##parLapply time----------------

parLapply_time <- system.time({
  
  cl <- makeCluster(detectCores() - 1)
  iterator <- irnorm(n = 5, mean = 1, sd = 1)
  
  dat <- replicate(3, nextElem(iterator))
  
  clusterExport(cl, "dat")
  
  maxs <- parLapply(cl, 1:3, function(i) {
    max(dat[, i])
  })  ## returns list
  
  stopCluster(cl)
  
  
})



t2 <- rbind(foreach_do_time, foreach_dopar_time, replicate_time, parLapply_time)

knitr::kable(t2, caption = "Times taken for each method to find the maximum of a length-3 vector generated by irnorm()")


```